"""
Test dashboard fixes for accuracy metrics and model retraining
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import pandas as pd
import numpy as np
from datetime import datetime
import traceback

def test_accuracy_metrics():
    """Test the fixed accuracy metrics calculation"""
    print("üéØ Testing Accuracy Metrics Calculation...")
    
    try:
        from predictor import GoldPredictor
        
        predictor = GoldPredictor()
        
        print("  - Testing accuracy analysis...")
        accuracy_result = predictor.analyze_prediction_accuracy(days=30)
        
        if accuracy_result is None:
            print("  ‚ùå Accuracy analysis returned None")
            return False
        
        if 'error' in accuracy_result:
            print(f"  ‚ö†Ô∏è Accuracy analysis returned error: {accuracy_result['error']}")
            # Still count as working if it returns structured error
            return True
        
        print(f"  ‚úÖ Accuracy metrics calculated successfully:")
        print(f"    - Accuracy: {accuracy_result['accuracy']:.3f}")
        print(f"    - Precision: {accuracy_result['precision']:.3f}")
        print(f"    - Recall: {accuracy_result['recall']:.3f}")
        print(f"    - Total predictions: {accuracy_result['total_predictions']}")
        print(f"    - Data points: {accuracy_result.get('data_points', 'N/A')}")
        print(f"    - Features used: {accuracy_result.get('features_used', 'N/A')}")
        
        return True
        
    except Exception as e:
        print(f"  ‚ùå Accuracy metrics test failed: {e}")
        traceback.print_exc()
        return False

def test_model_retraining():
    """Test the fixed model retraining functionality"""
    print("\nüîÑ Testing Model Retraining...")
    
    try:
        from updater import GoldModelUpdater
        
        updater = GoldModelUpdater()
        
        print("  - Testing force retrain functionality...")
        retrain_result = updater.force_retrain_now()
        
        if retrain_result:
            print("  ‚úÖ Model retraining completed successfully")
            
            # Test if model can be loaded after retraining
            from model_trainer import GoldModelTrainer
            trainer = GoldModelTrainer()
            
            model, features, metadata = trainer.load_model()
            if model is not None:
                print(f"  ‚úÖ Retrained model loaded successfully with {len(features)} features")
                return True
            else:
                print("  ‚ùå Failed to load retrained model")
                return False
        else:
            print("  ‚ùå Model retraining failed")
            return False
            
    except Exception as e:
        print(f"  ‚ùå Model retraining test failed: {e}")
        traceback.print_exc()
        return False

def test_dashboard_integration():
    """Test dashboard integration of both fixes"""
    print("\nüñ•Ô∏è Testing Dashboard Integration...")
    
    try:
        from predictor import GoldPredictor
        
        predictor = GoldPredictor()
        
        print("  - Testing comprehensive recommendation (includes accuracy)...")
        comprehensive_rec = predictor.get_comprehensive_trading_recommendation()
        
        if comprehensive_rec and 'prediction' in comprehensive_rec:
            print(f"  ‚úÖ Comprehensive recommendation working: {comprehensive_rec['prediction']['signal']}")
        else:
            print("  ‚ùå Comprehensive recommendation failed")
            return False
        
        print("  - Testing enhanced recommendation (includes macro factors)...")
        enhanced_rec = predictor.get_enhanced_comprehensive_recommendation()
        
        if enhanced_rec and 'macro_analysis' in enhanced_rec:
            print(f"  ‚úÖ Enhanced recommendation working with macro analysis")
            top_factors = enhanced_rec['macro_analysis'].get('top_factors', [])
            print(f"    - Top factors available: {len(top_factors)}")
        else:
            print("  ‚ùå Enhanced recommendation failed")
            return False
        
        return True
        
    except Exception as e:
        print(f"  ‚ùå Dashboard integration test failed: {e}")
        traceback.print_exc()
        return False

def main():
    """Run dashboard fixes tests"""
    print("üéØ DASHBOARD FIXES TEST")
    print("=" * 50)
    
    results = {}
    
    # Test each fix
    results['accuracy_metrics'] = test_accuracy_metrics()
    results['model_retraining'] = test_model_retraining()
    results['dashboard_integration'] = test_dashboard_integration()
    
    # Summary
    print("\n" + "=" * 50)
    print("üìä DASHBOARD FIXES TEST SUMMARY")
    print("=" * 50)
    
    for component, status in results.items():
        status_icon = "‚úÖ" if status else "‚ùå"
        print(f"{status_icon} {component.replace('_', ' ').title()}: {'WORKING' if status else 'FAILED'}")
    
    working_components = sum(results.values())
    total_components = len(results)
    
    print(f"\nüéØ Overall Status: {working_components}/{total_components} components working")
    
    if working_components == total_components:
        print("üéâ All dashboard fixes successful!")
        print("üìà Dashboard should now show:")
        print("  ‚úÖ Accurate prediction metrics")
        print("  ‚úÖ Working model retraining")
        print("  ‚úÖ Enhanced correlations")
    else:
        print("‚ö†Ô∏è Some issues remain - check details above")
    
    return results

if __name__ == "__main__":
    main()
